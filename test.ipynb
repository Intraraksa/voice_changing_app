{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403443e3-8553-4b64-a0bd-e1534e85836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import argparse\n",
    "import onnxruntime as rt\n",
    "import numpy as np\n",
    "from inference_trt import init_decoder_inputs\n",
    "from IPython.display import Audio\n",
    "import models\n",
    "from inference import checkpoint_from_distributed, unwrap_distributed, load_and_setup_model, prepare_input_sequence\n",
    "from tacotron2_common.utils import to_gpu, get_mask_from_lengths\n",
    "\n",
    "# Load model.onnx form directory\n",
    "encoder = rt.InferenceSession('model_onnx/encoder_2.onnx') \n",
    "decoder = rt.InferenceSession('model_onnx/decoder_iter_2.onnx')\n",
    "postnet = rt.InferenceSession('model_onnx/postnet_2.onnx')\n",
    "waveglow = rt.InferenceSession('model_onnx/waveglow.onnx')\n",
    "\n",
    "\n",
    "text = input(\"please enter your text: \")\n",
    "\n",
    "while text:\n",
    "\n",
    "    ## Encoder \n",
    "    input_length = [50]\n",
    "    sequences, lengths = prepare_input_sequence([text],cpu_run=True)\n",
    "    sequences =  np.int64(sequences.cpu())\n",
    "    while len(sequences) < input_length[0]:\n",
    "        sequences = np.append(sequences,0)\n",
    "    sequences = np.expand_dims(sequences,0)\n",
    "    memory, processed_memory, lens = encoder.run([\"memory\",\"processed_memory\",\"lens\"],{\"sequences\":sequences,\"sequence_lengths\":input_length})\n",
    "    memory, processed_memory, lens = torch.tensor(memory),torch.tensor(processed_memory),torch.tensor(lens)\n",
    "\n",
    "    ## Decoder_iter\n",
    "    mel_lengths = np.zeros([memory.size(0)], dtype=np.int32)\n",
    "    not_finished = np.ones([memory.size(0)], dtype=np.int32)\n",
    "    mel_outputs, gate_outputs, alignments = (np.zeros(1), np.zeros(1), np.zeros(1))\n",
    "\n",
    "\n",
    "    (decoder_input, attention_hidden, attention_cell, decoder_hidden,\n",
    "         decoder_cell, attention_weights, attention_weights_cum,\n",
    "         attention_context, memory, processed_memory,\n",
    "         mask) = init_decoder_inputs(memory, processed_memory, torch.tensor(input_length))\n",
    "\n",
    "    (decoder_input, attention_hidden, attention_cell, decoder_hidden,decoder_cell, attention_weights, attention_weights_cum,attention_context, memory, processed_memory,mask)  = decoder_input.numpy(), attention_hidden.numpy(), attention_cell.numpy(), decoder_hidden.numpy(),decoder_cell.numpy(), attention_weights.numpy(), attention_weights_cum.numpy(),attention_context.numpy(),memory.numpy(), processed_memory.numpy(),mask.numpy()\n",
    "\n",
    "    gate_threshold = 0.6\n",
    "    max_decoder_steps = 1000\n",
    "    first_iter = True\n",
    "\n",
    "    while True:\n",
    "        decoder_output_name = [\"decoder_output\", \"gate_prediction\",\"out_attention_hidden\", \"out_attention_cell\",\"out_decoder_hidden\", \"out_decoder_cell\",\"out_attention_weights\", \"out_attention_weights_cum\",\"out_attention_context\"]\n",
    "        decoder_input_element = {\"decoder_input\":decoder_input, \"attention_hidden\": attention_hidden, \"attention_cell\":attention_cell, \"decoder_hidden\":decoder_hidden ,\"decoder_cell\":decoder_cell, \"attention_weights\":attention_weights, \"attention_weights_cum\":attention_weights_cum,\"attention_context\":attention_context, \"memory\":memory, \"processed_memory\":processed_memory,\"mask\":mask}\n",
    "\n",
    "        (mel_output, gate_output,\n",
    "                     attention_hidden, attention_cell,\n",
    "                     decoder_hidden, decoder_cell,\n",
    "                     attention_weights, attention_weights_cum,\n",
    "                     attention_context) = decoder.run(decoder_output_name , decoder_input_element)\n",
    "\n",
    "        if first_iter:\n",
    "            mel_outputs = np.expand_dims(mel_output, 2)\n",
    "            gate_outputs = np.expand_dims(gate_output, 2)\n",
    "            alignments = np.expand_dims(attention_weights, 2)\n",
    "            first_iter = False\n",
    "        else:\n",
    "            mel_outputs = np.concatenate((mel_outputs, np.expand_dims(mel_output, 2)), 2)\n",
    "            gate_outputs = np.concatenate((gate_outputs, np.expand_dims(gate_output, 2)), 2)\n",
    "            alignments =np.concatenate((alignments, np.expand_dims(attention_weights, 2)), 2)\n",
    "\n",
    "        dec = torch.le(torch.sigmoid(torch.Tensor(gate_output)), gate_threshold).to(torch.int32).squeeze(1)\n",
    "        not_finished = not_finished*dec.numpy()\n",
    "        mel_lengths += not_finished\n",
    "\n",
    "        if np.sum(not_finished) == 0:\n",
    "                print(\"Stopping after \",mel_outputs.size,\" decoder steps\")\n",
    "                break\n",
    "        if mel_outputs.size == max_decoder_steps:\n",
    "            print(\"Warning! Reached max decoder steps\")\n",
    "            break\n",
    "\n",
    "        decoder_input = mel_output\n",
    "\n",
    "    #postnet\n",
    "    mel_outputs_postnet = postnet.run(['mel_outputs_postnet'],{'mel_outputs':mel_outputs})\n",
    "\n",
    "    stride = 256 # value from waveglow upsample\n",
    "    n_group = 8\n",
    "    z_size2 = (mel_outputs_postnet[0].shape[2]*stride)//n_group\n",
    "    z = np.random.randn(1, n_group, z_size2)\n",
    "    audio = waveglow.run(['audio'],{'mel':mel_outputs_postnet[0].astype('float32'),'z':z.astype('float32')})\n",
    "    audio_numpy = np.squeeze(audio[0])\n",
    "    audio_numpy.shape\n",
    "    rate = 22050\n",
    "    Audio(audio_numpy, rate=rate)\n",
    "    \n",
    "    text = input(\"please enter your text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54aa2ac5-cf3f-4eb3-a1e1-9bd1cea61990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\n_int/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\n_int/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\n_int/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2_pyt_ckpt_amp/versions/19.09.0/files/nvidia_tacotron2pyt_fp16_20190427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tacotron2(\n",
       "  (embedding): Embedding(148, 512)\n",
       "  (encoder): Encoder(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (prenet): Prenet(\n",
       "      (layers): ModuleList(\n",
       "        (0): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n",
       "        )\n",
       "        (1): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attention_rnn): LSTMCell(768, 1024)\n",
       "    (attention_layer): Attention(\n",
       "      (query_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n",
       "      )\n",
       "      (memory_layer): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=512, out_features=128, bias=False)\n",
       "      )\n",
       "      (v): LinearNorm(\n",
       "        (linear_layer): Linear(in_features=128, out_features=1, bias=False)\n",
       "      )\n",
       "      (location_layer): LocationLayer(\n",
       "        (location_conv): ConvNorm(\n",
       "          (conv): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n",
       "        )\n",
       "        (location_dense): LinearNorm(\n",
       "          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder_rnn): LSTMCell(1536, 1024, bias=1)\n",
       "    (linear_projection): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=80, bias=True)\n",
       "    )\n",
       "    (gate_layer): LinearNorm(\n",
       "      (linear_layer): Linear(in_features=1536, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (postnet): Postnet(\n",
       "    (convolutions): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvNorm(\n",
       "          (conv): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        )\n",
       "        (1): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tacotron2 = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tacotron2', model_math='fp16')\n",
    "tacotron2 = tacotron2.to('cuda')\n",
    "tacotron2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b11d2577-c671-4571-aec9-0aad75b68d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\n_int/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WaveGlow(\n",
       "  (upsample): ConvTranspose1d(80, 80, kernel_size=(1024,), stride=(256,))\n",
       "  (WN): ModuleList(\n",
       "    (0): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (1): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (3): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(4, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 8, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (4): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (5): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (6): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (7): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(3, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 6, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (8): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (9): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (10): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (11): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(32,), dilation=(32,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(64,), dilation=(64,))\n",
       "        (7): Conv1d(512, 1024, kernel_size=(3,), stride=(1,), padding=(128,), dilation=(128,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (cond_layers): ModuleList(\n",
       "        (0): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (1): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (2): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (3): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (4): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (5): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (6): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (7): Conv1d(640, 1024, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (start): Conv1d(2, 512, kernel_size=(1,), stride=(1,))\n",
       "      (end): Conv1d(512, 4, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (convinv): ModuleList(\n",
       "    (0): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (1): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (2): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (3): Invertible1x1Conv(\n",
       "      (conv): Conv1d(8, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (4): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (5): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (6): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (7): Invertible1x1Conv(\n",
       "      (conv): Conv1d(6, 6, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (8): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (9): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (10): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "    (11): Invertible1x1Conv(\n",
       "      (conv): Conv1d(4, 4, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveglow = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_waveglow', model_math='fp16')\n",
    "waveglow = waveglow.remove_weightnorm(waveglow)\n",
    "waveglow = waveglow.to('cuda')\n",
    "waveglow.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9c825d8-6825-4a57-abc4-1909599cc3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello world, I missed you so much.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe45139-ef82-4455-be8e-bf8f811dabbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\n_int/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    }
   ],
   "source": [
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_tts_utils')\n",
    "sequences, lengths = utils.prepare_input_sequence([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1590960c-817e-4f2a-bd49-9710732719e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    mel, _, _ = tacotron2.infer(sequences, lengths)\n",
    "    audio = waveglow.infer(mel)\n",
    "audio_numpy = audio[0].data.cpu().numpy()\n",
    "rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe668c7-c5fe-4e31-a89a-6ae52d49278e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
